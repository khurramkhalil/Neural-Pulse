{
  "project": {
    "name": "Neural Pulse",
    "version": "0.1.0",
    "description": "Runtime Verification Framework for Adversarial Defense Against SECA Attacks",
    "target_conference": "NeurIPS/ICLR/CCS",
    "base_threat": "SECA (Semantically Equivalent and Coherent Attacks)",
    "defense_method": "Signal Temporal Logic (STL) Runtime Verification"
  },
  "infrastructure": {
    "cluster": "Nautilus K8s",
    "namespace": "gp-engine-mizzou-dcps",
    "gpu_type": "NVIDIA-A100-80GB",
    "container_image": "khurramkhalil/gpa-emergency:latest"
  },
  "signals": {
    "entropy": {
      "description": "Shannon entropy of softmax distribution at each token step",
      "hypothesis": "SECA attacks cause prolonged high entropy (waffling)"
    },
    "attention_dispersion": {
      "description": "Maximum normalized attention to context tokens (sink-removed)",
      "hypothesis": "SECA attacks cause detachment from context (low context attention)",
      "version": "v2",
      "improvements": [
        "Removed attention sink (first token)",
        "Normalized by total attention budget",
        "Track max attention to ANY context token (not average)"
      ]
    }
  },
  "validation": {
    "approach": "oracle_only",
    "oracle": {
      "method": "DeBERTa-v3-large NLI + Factuality check",
      "confidence_threshold": 0.9,
      "purpose": "Label traces by ACTUAL outcome (hallucination vs correct), not prompt type",
      "implementation": "datasets/oracle_validator.py"
    },
    "expected_label_distribution": {
      "seca_prompts_to_hallucination": 0.85,
      "seca_prompts_to_correct": 0.15,
      "mmlu_prompts_to_hallucination": 0.05,
      "mmlu_prompts_to_correct": 0.95
    }
  },
  "future_work": {
    "hybrid_validation": {
      "description": "Combine human expert labels (200 traces) with oracle labels (1800 traces)",
      "human_expert_subset": {
        "size": 200,
        "target_agreement": "Cohen's κ > 0.85",
        "purpose": "Gold standard + calibrate oracle thresholds"
      },
      "benefits": [
        "Higher scientific rigor (gold standard ground truth)",
        "Inter-annotator agreement reporting (Cohen's κ)",
        "Oracle calibration on human labels",
        "Transparency: report both human and oracle performance"
      ],
      "priority": "High (enhances paper quality for top-tier venue)"
    },
    "organic_hallucination_control": {
      "description": "Add misconception QA and ambiguous questions to dataset",
      "source": "TruthfulQA benchmark",
      "purpose": "Distinguish SECA attacks from organic hallucinations on misleading prompts",
      "examples": [
        "What happens if you crack your knuckles? (common myth)",
        "How many sides does a pentagon have? (trick question variants)"
      ],
      "priority": "Medium (strengthens ablation studies)"
    }
  },
  "datasets": {
    "attack": {
      "source": "SECA",
      "repo": "https://github.com/Buyun-Liang/SECA",
      "description": "Adversarial prompts generated by SECA"
    },
    "normal": {
      "source": "MMLU",
      "description": "Multiple-choice question answering dataset for clean prompts"
    }
  },
  "stl_library": "rtamt",
  "models": {
    "victim": "Llama-3-8B",
    "alternatives": ["Llama-2-13B", "Qwen-2.5-7B", "GPT-4o-Mini"]
  }
}
